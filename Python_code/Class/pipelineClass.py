#This class houses the methods which are relevant 
#For fiting gaussians to a galactic spectra, 
#fitting template spectra to an observed spectrum 
#and estimating the galactic physical properties 

#import the relevant modules
import os, sys, numpy as np, random, matplotlib.mlab as mlab, matplotlib.pyplot as plt, math, matplotlib.cm as cm
from matplotlib.backends.backend_pdf import PdfPages
from pylab import *
from matplotlib.colors import LogNorm
import numpy.polynomial.polynomial as poly
import lmfit
from lmfit.models import GaussianModel, ExponentialModel, LorentzianModel, VoigtModel, PolynomialModel

#add my toolkit.py file to the PYTHONPATH
sys.path.append('/Users/owenturner/Documents/PhD/SUPA_Courses/AdvancedDataAnalysis/Homeworks')

#and import the toolkit
import toolkit
from astropy.io import fits

####################################################################

class pipelineOps(object):
	#Initialiser creates an instance of the spectrumFit object 
	def __init__(self):
		self.self = self

####################################################################

######################################################################################
#MODULE: computeOffset
#
#PURPOSE:
#Take the object image after calibration, along with a sky frame, bad pixel frame and 
#the lcal frame and homogenise the readout columns, so that after subtraction gives 0
#
#INPUTS:
#
#			objectFile: The object image to be corrected 	
#			skyFile: The sky image taken directly before or after the object frame
#			badPMap: The bad pixel frame generated by the pipeline
#			lcalMap: The calibration frame generated by the pipeline
#
#OUTPUTS: 	newObjData: The corrected 2048x2048 object arrray which can then be saved
#						
#
#USAGE: 	newObjData = computeOffset(objectFile, skyFile, badPMap, lcalMap)
#######################################################################################	

	
	#Access the primary extension, later this will be looped  
	def computeOffset(self, objectFile, skyFile, badPMap, lcalMap): 
		#Set up vector to house the corrected extensions
		correctedExtensions=[]
		#Read in the tables of data
		table_o = fits.open(objectFile)
		fitsHeader = table_o[0].header
		print fitsHeader
		table_s = fits.open(skyFile)
		bad_pixel_table = fits.open(badPMap)

		#Now choose the correct rotation angle 
		lcal_table = fits.open(lcalMap)
		#This is a list of all possible rotation angles 
		angleList = np.array([0, 60, 120, 180, 240, 300])
		#Select the ocs.rot.naangle keyword 
		obsAngle = table_o[0].header["HIERARCH ESO OCS ROT NAANGLE"]
		#Find where the difference between the observed and idealised angle is minimum
		newAngleList = obsAngle - angleList
		n = newAngleList.argmin()
		obsAngleNew = angleList[n]


		#Find the extension to which this corresponds
		val = 0
		if obsAngleNew == 0:
			val = 1 
		elif obsAngleNew == 60:
			val = 4
		elif obsAngleNew == 120:
			val = 7
		elif obsAngleNew == 180: 
			val = 10
		elif obsAngleNew == 240:
			val = 13
		elif obsAngleNew == 300:
			val = 16		
		print val	


		#Loop over the fits image extensions, do the same each time
		for count in range(1,4):
			print val
			data_o = table_o[count].data
			data_s = table_s[count].data
			bad_pixel_data = bad_pixel_table[count].data			
			lcal_data = lcal_table[val].data

			#Now we have both the object and sky data these are 2D arrays, 
			#essentially a matrix where each number represents a pixel flux, 
			#And the location of the number in the matrix represents the 
			#Pixel position on the detector, which in turn corresponds to the 
			#objects position on the sky. Need to slice this 2D array into a 
			#1D array of 2D arrays, each of which is 64 pixels wide 
			#so that I can examine these in turn and loop over them 

			#Counters for the slicing 
			x = 0
			y = 64

			#1D arrays to host the data 
			skyArray = []
			objArray = []
			badPArray = []
			lcalArray = []

			for i in range(32):
			   
			   #Slice each of the data files into 32 columns of 64 pixels width
			   newObjectArray = data_o[:,x:y]
			   newSkyArray = data_s[:,x:y]
			   newPArray = bad_pixel_data[:,x:y]
			   newCalArray = lcal_data[:,x:y]
			   objArray.append(newObjectArray)
			   skyArray.append(newSkyArray)
			   badPArray.append(newPArray)
			   lcalArray.append(newCalArray)

			   #Add 64 to the counters each time to create the slices
			   x += 64
			   y += 64

			#Now wanto to read in the lcal and the bad pixel map, 
			#To get a list of the pixel indices which should be averaged
			#First need to slice this in the same way as the other file 
			#Then simply find the bad pixel and the lcal positions, hide 
			#these as nan and compute the median in each 64 pixel column 
			#from everything that isn't nan, then apply the correction to the 
			#data before stitching everything back together as a data file
			#And feeding back into the pipeline at the appropriate location

			#Redefine objArray and sky array, do manipulations to temp
			objTemp = copy(objArray)
			skyTemp = copy(skyArray)
			#Start the loop for all the columns in the Array vectors 
			for num in range(len(objArray)):


				#Find the coordinates of the bad pixels and the slitlets 
				bad_pixel_coords = np.where(badPArray[num] == 0)
				lcal_pixel_coords = np.where(lcalArray[num] > 0)

				#Loop through the first 2048 x 64 data and sky columns and mask off these coords
				#Then compute the median in both columns. If median sky > median obj, add the difference 
				#between the median values to the obj. If the other way around, decrement

				#Loop around the bad pixel locations
				for i in range(len(bad_pixel_coords[0])):
					#Because of the way np.where works, need to define the x and y coords in this way
					xcoord = bad_pixel_coords[0][i]
					ycoord = bad_pixel_coords[1][i]
					#Now set all positions where there is a dead pixel to np.nan in the object and sky
					objTemp[num][xcoord][ycoord] = np.nan
					skyTemp[num][xcoord][ycoord] = np.nan

				#Loop around the slitlet positions
				for i in range(len(lcal_pixel_coords[0])):
					#Do the same, this time for the slitlet positions (substantially more will have a value)
					xcoord = lcal_pixel_coords[0][i]
					ycoord = lcal_pixel_coords[1][i]
					#Set all of these locations to nan 
					objTemp[num][xcoord][ycoord] = np.nan
					skyTemp[num][xcoord][ycoord] = np.nan


				#Now all the pixels that shouldn't be included in the median 
				#have value nan. Can then just do np.nanmean(objTemp) which will ignore nan's
				#then repeat the process for the sky, compare the mean's, compute and apply the offset.

				obj_mean = np.nanmedian(objTemp[num])
				sky_mean = np.nanmedian(skyTemp[num])
				print sky_mean
				print obj_mean

				#Need to compare the two medians to see how to apply the offset.
				#If the sky is brighter, add the difference to the object image

				if sky_mean > obj_mean:
					objArray[num] += abs(sky_mean - obj_mean)
				elif obj_mean > sky_mean:
					objArray[num] -= abs(obj_mean - sky_mean)	

			#Have now made the correction to all 32 of the 64 pixel width columns.
			#All that is left to do is stitch the objArray arrays back together to 
			#give a single 2048x2048 array.
			newObjData = np.hstack(objArray)
			correctedExtensions.append(newObjData)
			if count == 1:
				print 'Computed First Correction'
			elif count == 2:
				print 'Computed Second Correction'
			elif count == 3: 
				print 'Computed Third Correction'			
			val += 1				
		#Create the object fits file with the three corrected extensions
		fileName = objectFile + '_Corrected'
		#Note that the readout complained about the header not being 
		#in the correct fits format
		fits.writeto(fileName, data = [], header=fitsHeader, clobber=True)
		fits.append(fileName, data=correctedExtensions[0])	
		fits.append(fileName, data=correctedExtensions[1])	
		fits.append(fileName, data=correctedExtensions[2])	

